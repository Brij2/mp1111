{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:12:08.176151Z",
          "iopub.status.busy": "2021-06-28T21:12:08.175772Z",
          "iopub.status.idle": "2021-06-28T21:12:08.188567Z",
          "shell.execute_reply": "2021-06-28T21:12:08.187647Z",
          "shell.execute_reply.started": "2021-06-28T21:12:08.176065Z"
        },
        "id": "YMm4qVv5qtGE",
        "outputId": "46034115-6222-4708-e9ef-f7f407130943"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "from IPython.display import clear_output\n",
        "print(platform.platform())\n",
        "\n",
        "def resolve_dir(Dir):\n",
        "    if not os.path.exists(Dir):\n",
        "        os.mkdir(Dir)\n",
        "\n",
        "def reset_path(Dir):\n",
        "    if not os.path.exists(Dir):\n",
        "        os.mkdir(Dir)\n",
        "    else:\n",
        "        os.system('rm -f {}/*'.format( Dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:12:12.539247Z",
          "iopub.status.busy": "2021-06-28T21:12:12.538912Z",
          "iopub.status.idle": "2021-06-28T21:12:18.360385Z",
          "shell.execute_reply": "2021-06-28T21:12:18.359448Z",
          "shell.execute_reply.started": "2021-06-28T21:12:12.539218Z"
        },
        "id": "m77ifGzHqtBg",
        "outputId": "cccebfce-fcbf-4a7d-802b-4de91b6e4772"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(73)\n",
        "TPU_INIT = False\n",
        "\n",
        "if TPU_INIT:\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "        tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    \n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime!')\n",
        "else:\n",
        "    !nvidia-smi;  \n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:12:26.392432Z",
          "iopub.status.busy": "2021-06-28T21:12:26.392057Z",
          "iopub.status.idle": "2021-06-28T21:12:27.147421Z",
          "shell.execute_reply": "2021-06-28T21:12:27.146411Z",
          "shell.execute_reply.started": "2021-06-28T21:12:26.392397Z"
        },
        "id": "DwRUpYt5qs1l"
      },
      "outputs": [],
      "source": [
        "MyDrive = '/kaggle/working'\n",
        "PROJECT_DIR = 'C:\\\\Users\\\\Lenovo\\\\Desktop\\\\MP 1\\\\Real Life Violence Dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xelnEP2OsH_7"
      },
      "source": [
        "## **Preprocessing**\n",
        "+ **Getting frames form video**\n",
        "+ **some image argumentations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:13:35.503988Z",
          "iopub.status.busy": "2021-06-28T21:13:35.503640Z",
          "iopub.status.idle": "2021-06-28T21:13:37.178990Z",
          "shell.execute_reply": "2021-06-28T21:13:37.178190Z",
          "shell.execute_reply.started": "2021-06-28T21:13:35.503957Z"
        },
        "id": "VNftx0E_sH_9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import imageio\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug as ia\n",
        "\n",
        "IMG_SIZE = 128\n",
        "ColorChannels = 3\n",
        "\n",
        "def video_to_frames(video):\n",
        "    vidcap = cv2.VideoCapture(video)\n",
        "    \n",
        "    import math\n",
        "    rate = math.floor(vidcap.get(3))\n",
        "    count = 0\n",
        "    \n",
        "    ImageFrames = []\n",
        "    while vidcap.isOpened():\n",
        "        ID = vidcap.get(1)\n",
        "        success, image = vidcap.read()\n",
        "        \n",
        "        if success:\n",
        "            # skipping frames to avoid duplications \n",
        "            if (ID % 7 == 0):\n",
        "                flip = iaa.Fliplr(1.0)\n",
        "                zoom = iaa.Affine(scale=1.3)\n",
        "                random_brightness = iaa.Multiply((1, 1.3))\n",
        "                rotate = iaa.Affine(rotate=(-25, 25))\n",
        "                \n",
        "                image_aug = flip(image = image)\n",
        "                image_aug = random_brightness(image = image_aug)\n",
        "                image_aug = zoom(image = image_aug)\n",
        "                image_aug = rotate(image = image_aug)\n",
        "                \n",
        "                rgb_img = cv2.cvtColor(image_aug, cv2.COLOR_BGR2RGB)\n",
        "                resized = cv2.resize(rgb_img, (IMG_SIZE, IMG_SIZE))\n",
        "                ImageFrames.append(resized)\n",
        "                \n",
        "            count += 1\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    vidcap.release()\n",
        "    \n",
        "    return ImageFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:13:41.414231Z",
          "iopub.status.busy": "2021-06-28T21:13:41.413870Z",
          "iopub.status.idle": "2021-06-28T21:17:29.584414Z",
          "shell.execute_reply": "2021-06-28T21:17:29.581822Z",
          "shell.execute_reply.started": "2021-06-28T21:13:41.414198Z"
        },
        "id": "VtjFbXZKsH_-",
        "outputId": "26ea2589-1b55-47d5-947c-7bb5bd21f999"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# VideoDataDir = PROJECT_DIR + '/Real Life Violence Dataset'\n",
        "VideoDataDir = PROJECT_DIR\n",
        "print('we have \\n{} Violence videos \\n{} NonViolence videos'.format(\n",
        "              len(os.listdir(VideoDataDir + '/Violence')), \n",
        "              len(os.listdir(VideoDataDir + '/NonViolence'))))\n",
        "\n",
        "X_original = []\n",
        "y_original = []\n",
        "\n",
        "print('i choose 700 videos out of 2000, cuz of memory issue')\n",
        "CLASSES = [\"NonViolence\", \"Violence\"]\n",
        "#700 <- 350 + 350\n",
        "\n",
        "for category in os.listdir(VideoDataDir):\n",
        "    path = os.path.join(VideoDataDir, category)\n",
        "    class_num = CLASSES.index(category)\n",
        "    for i, video in enumerate(tqdm(os.listdir(path)[0:350])):\n",
        "        frames = video_to_frames(path + '/' + video)\n",
        "        for j, frame in enumerate(frames):\n",
        "            X_original.append(frame)\n",
        "            y_original.append(class_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:18:34.638320Z",
          "iopub.status.busy": "2021-06-28T21:18:34.637958Z",
          "iopub.status.idle": "2021-06-28T21:18:34.864211Z",
          "shell.execute_reply": "2021-06-28T21:18:34.863222Z",
          "shell.execute_reply.started": "2021-06-28T21:18:34.638286Z"
        },
        "id": "0Knwy2OjsH__",
        "outputId": "53453a2c-9bc7-4210-8736-b89ce5819e15"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_original = np.array(X_original).reshape(-1 , IMG_SIZE * IMG_SIZE * 3)\n",
        "y_original = np.array(y_original)\n",
        "len(X_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:18:40.130114Z",
          "iopub.status.busy": "2021-06-28T21:18:40.129780Z",
          "iopub.status.idle": "2021-06-28T21:18:42.322266Z",
          "shell.execute_reply": "2021-06-28T21:18:42.321377Z",
          "shell.execute_reply.started": "2021-06-28T21:18:40.130083Z"
        },
        "id": "ziCGqqa9sIAA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "stratified_sample = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=73)\n",
        "\n",
        "for train_index, test_index in stratified_sample.split(X_original, y_original):\n",
        "    X_train, X_test = X_original[train_index], X_original[test_index]\n",
        "    y_train, y_test = y_original[train_index], y_original[test_index]\n",
        "\n",
        "X_train_nn = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n",
        "X_test_nn = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvmfQMM0p46i"
      },
      "source": [
        "## **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:18:46.747492Z",
          "iopub.status.busy": "2021-06-28T21:18:46.747115Z",
          "iopub.status.idle": "2021-06-28T21:18:56.074221Z",
          "shell.execute_reply": "2021-06-28T21:18:56.073342Z",
          "shell.execute_reply.started": "2021-06-28T21:18:46.747463Z"
        },
        "id": "loeXLm9-sIAB"
      },
      "outputs": [],
      "source": [
        "!pip install imutils\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:19:00.024214Z",
          "iopub.status.busy": "2021-06-28T21:19:00.023698Z",
          "iopub.status.idle": "2021-06-28T21:19:00.097339Z",
          "shell.execute_reply": "2021-06-28T21:19:00.096328Z",
          "shell.execute_reply.started": "2021-06-28T21:19:00.024167Z"
        },
        "id": "f5SLkPZ2I01J"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dropout,Flatten,Dense\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# >>> from sklearn.linear_model import LinearRegression as lm\n",
        "# >>> model=lm().fit(x_train,y_train)\n",
        "# >>> predictions=model.predict(x_test)\n",
        "# >>> import matplotlib.pyplot as plt\n",
        "# >>> plt.scatter(y_test,predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-06-28T21:19:03.585235Z",
          "iopub.status.busy": "2021-06-28T21:19:03.584867Z",
          "iopub.status.idle": "2021-06-28T21:19:06.799324Z",
          "shell.execute_reply": "2021-06-28T21:19:06.798517Z",
          "shell.execute_reply.started": "2021-06-28T21:19:03.585199Z"
        },
        "id": "dNsCZbY3p8VM",
        "outputId": "431b8715-b9d1-4bb0-eb7e-5758027c14ac"
      },
      "outputs": [],
      "source": [
        "epochs = 40\n",
        "\n",
        "from keras import regularizers\n",
        "kernel_regularizer = regularizers.l2(0.0001)\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "def load_layers():\n",
        "    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, ColorChannels))\n",
        "    baseModel = MobileNetV2(pooling='avg',\n",
        "                            include_top=False, \n",
        "                            input_tensor=input_tensor)\n",
        "    \n",
        "    headModel = baseModel.output   \n",
        "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
        "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "    for layer in baseModel.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    print(\"Compiling model...\")\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                    optimizer='adam',\n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "if TPU_INIT:\n",
        "    with tpu_strategy.scope():\n",
        "        model = load_layers()\n",
        "else:\n",
        "    model = load_layers()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:19:22.163129Z",
          "iopub.status.busy": "2021-06-28T21:19:22.162673Z",
          "iopub.status.idle": "2021-06-28T21:19:22.176337Z",
          "shell.execute_reply": "2021-06-28T21:19:22.175519Z",
          "shell.execute_reply.started": "2021-06-28T21:19:22.163083Z"
        },
        "id": "Ot4-s-9rLwF4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "patience = 3\n",
        "\n",
        "start_lr = 0.00001\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.00005\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "if TPU_INIT:\n",
        "    max_lr = max_lr * tpu_strategy.num_replicas_in_sync\n",
        "    batch_size = batch_size * tpu_strategy.num_replicas_in_sync\n",
        "\n",
        "rampup_epochs = 5\n",
        "sustain_epochs = 0\n",
        "exp_decay = .8\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < rampup_epochs:\n",
        "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "    elif epoch < rampup_epochs + sustain_epochs:\n",
        "        return max_lr\n",
        "    else:\n",
        "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "\n",
        "\n",
        "class myCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if ((logs.get('accuracy')>=0.999)):\n",
        "            print(\"\\nLimits Reached cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:19:28.031571Z",
          "iopub.status.busy": "2021-06-28T21:19:28.031227Z",
          "iopub.status.idle": "2021-06-28T21:19:28.388810Z",
          "shell.execute_reply": "2021-06-28T21:19:28.387749Z",
          "shell.execute_reply.started": "2021-06-28T21:19:28.031539Z"
        },
        "id": "-OB5GFdDsIAD"
      },
      "outputs": [],
      "source": [
        "end_callback = myCallback()\n",
        "\n",
        "lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=False)\n",
        "\n",
        "early_stopping = EarlyStopping(patience = patience, monitor='val_loss',\n",
        "                                 mode='min', restore_best_weights=True, \n",
        "                                 verbose = 1, min_delta = .00075)\n",
        "\n",
        "PROJECT_DIR = MyDrive + '/RiskDetection'\n",
        "\n",
        "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
        "\n",
        "os.system('rm -rf ./logs/')\n",
        "\n",
        "import datetime\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir = log_dir, write_graph=True, histogram_freq=1)\n",
        "\n",
        "checkpoint_filepath = 'ModelWeights.h5'\n",
        "\n",
        "model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                        save_weights_only=True,\n",
        "                                        monitor='val_loss',\n",
        "                                        mode='min',\n",
        "                                        verbose = 1,\n",
        "                                        save_best_only=True)\n",
        "\n",
        "\n",
        "callbacks = [end_callback, lr_callback, model_checkpoints, tensorboard_callback, early_stopping, lr_plat]\n",
        "\n",
        "if TPU_INIT:\n",
        "    callbacks = [end_callback, lr_callback, model_checkpoints, early_stopping, lr_plat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# >>> from sklearn.linear_model import LinearRegression as lm\n",
        "# >>> model=lm().fit(x_train,y_train)\n",
        "# >>> predictions=model.predict(x_test)\n",
        "# >>> import matplotlib.pyplot as plt\n",
        "# >>> plt.scatter(y_test,predictions)\n",
        "# import torch\n",
        "# model = torch.load('./model_grp29.h5')\n",
        "# print(model)\n",
        "from keras.models import load_model\n",
        "vis_model=load_model('./model_grp29.h5')\n",
        "print(vis_model.input)\n",
        "print(vis_model.output)\n",
        "prediction=vis_model.predict(X_test_nn)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction=vis_model.predict()\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(len(X_test_nn))\n",
        "# print(X_test_nn[0])\n",
        "import numpy as np\n",
        "import cv2\n",
        "size = 720*16//9, 720\n",
        "duration = 2\n",
        "fps = 25\n",
        "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (size[1], size[0]), False)\n",
        "for _ in range(fps * duration):\n",
        "    data = X_test_nn[0]\n",
        "    out.write(data)\n",
        "out.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": false,
        "execution": {
          "iopub.execute_input": "2021-06-28T21:19:34.188325Z",
          "iopub.status.busy": "2021-06-28T21:19:34.187954Z",
          "iopub.status.idle": "2021-06-28T21:40:04.073914Z",
          "shell.execute_reply": "2021-06-28T21:40:04.073018Z",
          "shell.execute_reply.started": "2021-06-28T21:19:34.188280Z"
        },
        "id": "MDFpuPolFYRc",
        "outputId": "ea444b27-b899-46b5-cc59-fe9ba7de6c9a"
      },
      "outputs": [],
      "source": [
        "print('Training head...')\n",
        "#model.load_weights('./Model_Weights.h5')\n",
        "\n",
        "history = model.fit(X_train_nn ,y_train, epochs=epochs,callbacks=callbacks,\n",
        "                        validation_data = (X_test_nn, y_test),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "print('\\nRestoring best Weights for MobileNetV2')\n",
        "model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:41:11.914827Z",
          "iopub.status.busy": "2021-06-28T21:41:11.914488Z",
          "iopub.status.idle": "2021-06-28T21:41:11.933416Z",
          "shell.execute_reply": "2021-06-28T21:41:11.932620Z",
          "shell.execute_reply.started": "2021-06-28T21:41:11.914793Z"
        },
        "id": "1s1W3C08sIAE"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def print_graph(item, index, history):\n",
        "    plt.figure()\n",
        "    train_values = history.history[item][0:index]\n",
        "    plt.plot(train_values)\n",
        "    test_values = history.history['val_' + item][0:index]\n",
        "    plt.plot(test_values)\n",
        "    plt.legend(['training','validation'])\n",
        "    plt.title('Training and validation '+ item)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "    plot = '{}.png'.format(item)\n",
        "    plt.savefig(plot)\n",
        "\n",
        "\n",
        "def get_best_epoch(test_loss, history):\n",
        "    for key, item in enumerate(history.history.items()):\n",
        "        (name, arr) = item\n",
        "        if name == 'val_loss':\n",
        "            for i in range(len(arr)):\n",
        "                if round(test_loss, 2) == round(arr[i], 2):\n",
        "                    return i\n",
        "                \n",
        "def model_summary(model, history):\n",
        "    print('---'*30)\n",
        "    test_loss, test_accuracy = model.evaluate(X_test_nn, y_test, verbose=0)\n",
        "\n",
        "    if history:\n",
        "        index = get_best_epoch(test_loss, history)\n",
        "        print('Best Epochs: ', index)\n",
        "\n",
        "        train_accuracy = history.history['accuracy'][index]\n",
        "        train_loss = history.history['loss'][index]\n",
        "\n",
        "        print('Accuracy on train:',train_accuracy,'\\tLoss on train:',train_loss)\n",
        "        print('Accuracy on test:',test_accuracy,'\\tLoss on test:',test_loss)\n",
        "        print_graph('loss', index, history)\n",
        "        print_graph('accuracy', index, history)\n",
        "        print('---'*30)                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:41:15.265817Z",
          "iopub.status.busy": "2021-06-28T21:41:15.265489Z",
          "iopub.status.idle": "2021-06-28T21:41:18.543465Z",
          "shell.execute_reply": "2021-06-28T21:41:18.542383Z",
          "shell.execute_reply.started": "2021-06-28T21:41:15.265788Z"
        },
        "id": "z4jTgDv7sIAE",
        "outputId": "2159afd8-d667-4ad1-c54c-bf32e4b2465b"
      },
      "outputs": [],
      "source": [
        "model_summary(model, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0eSBvicsIAF"
      },
      "source": [
        "## **Evaluation on test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:41:25.756227Z",
          "iopub.status.busy": "2021-06-28T21:41:25.755863Z",
          "iopub.status.idle": "2021-06-28T21:41:28.541319Z",
          "shell.execute_reply": "2021-06-28T21:41:28.540479Z",
          "shell.execute_reply.started": "2021-06-28T21:41:25.756189Z"
        },
        "id": "RDJb2EZDtwH2",
        "outputId": "e3685299-469c-40b1-e249-026cfcb2e4e2"
      },
      "outputs": [],
      "source": [
        "# evaluate the network\n",
        "print(\"Evaluating network...\")\n",
        "predictions = model.predict(X_test_nn)\n",
        "preds = predictions > 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(\"pred value:\",preds)\n",
        "type(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-28T21:41:29.601949Z",
          "iopub.status.busy": "2021-06-28T21:41:29.601622Z",
          "iopub.status.idle": "2021-06-28T21:41:29.957269Z",
          "shell.execute_reply": "2021-06-28T21:41:29.956236Z",
          "shell.execute_reply.started": "2021-06-28T21:41:29.601912Z"
        },
        "id": "NEiZpFUksIAF",
        "outputId": "2cdc7828-5347-46a9-eec1-83f386aa7065"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve, accuracy_score, classification_report, confusion_matrix\n",
        "corr_pred = metrics.confusion_matrix(y_test, preds)\n",
        "\n",
        "n_correct = np.int((corr_pred[0][0] + corr_pred[1][1]))\n",
        "print('> Correct Predictions:', n_correct)\n",
        "n_wrongs = np.int((corr_pred[0][1] + (corr_pred[1][0])))\n",
        "print('> Wrong Predictions:', n_wrongs)\n",
        "\n",
        "sns.heatmap(corr_pred,annot=True, fmt=\"d\",cmap=\"Blues\")\n",
        "plt.show()\n",
        "\n",
        "print(metrics.classification_report(y_test, preds, \n",
        "                           target_names=[\"NonViolence\", \"Violence\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-27T12:26:57.76156Z",
          "iopub.status.busy": "2021-06-27T12:26:57.761213Z",
          "iopub.status.idle": "2021-06-27T12:26:58.023373Z",
          "shell.execute_reply": "2021-06-27T12:26:58.02252Z",
          "shell.execute_reply.started": "2021-06-27T12:26:57.761526Z"
        },
        "id": "QC4GtxqMtt81"
      },
      "outputs": [],
      "source": [
        "args_model = \"model_grp29.h5\"\n",
        "model.save(args_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import time \n",
        "from keras.models import load_model\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from google.colab.patches import cv2_imshow\n",
        "from cv2 import imshow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getTime():\n",
        "  IST = pytz.timezone('Asia/Kolkata')\n",
        "  timeNow = datetime.now(IST)\n",
        "  return timeNow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imgenhance():\n",
        "  image1 = Image.open('savedImage.jpg')\n",
        "  curr_bri = ImageEnhance.Sharpness(image1)\n",
        "  new_bri = 1.3\n",
        "  img_brightened = curr_bri.enhance(new_bri)\n",
        "  im1 = img_brightened.save(\"bright.jpg\")\n",
        "\n",
        "  image2 = Image.open('bright.jpg')\n",
        "  curr_col = ImageEnhance.Color(image2)\n",
        "  new_col = 1.5\n",
        "  img_col = curr_col.enhance(new_col)\n",
        "  im2 = img_col.save(\"finalImage.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matplotlib.pyplot.imread\n",
        "# matplotlib.pyplot.imread(fname, format=None)[source]\n",
        "pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install google.colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# from google import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def imgenhance():\n",
        "  image1 = Image.open('savedImage.jpg')\n",
        "  curr_bri = ImageEnhance.Sharpness(image1)\n",
        "  new_bri = 1.3\n",
        "  img_brightened = curr_bri.enhance(new_bri)\n",
        "  im1 = img_brightened.save(\"bright.jpg\")\n",
        "\n",
        "  image2 = Image.open('bright.jpg')\n",
        "  curr_col = ImageEnhance.Color(image2)\n",
        "  new_col = 1.5\n",
        "  img_col = curr_col.enhance(new_col)\n",
        "  im2 = img_col.save(\"finalImage.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_faces(filename, result_list):\n",
        "  # load the image\n",
        "  data = pyplot.imread(filename)\n",
        "  # plot each face as a subplot\n",
        "  for i in range(len(result_list)):\n",
        "      # get coordinates\n",
        "      x1, y1, width, height = result_list[i]['box']\n",
        "      x2, y2 = x1 + width, y1 + height\n",
        "      # define subplot\n",
        "      pyplot.subplot(1, len(result_list), i+1)\n",
        "      pyplot.axis('off')\n",
        "      # plot face\n",
        "      pyplot.imshow(data[y1:y2, x1:x2])\n",
        "  # show the plot\n",
        "  pyplot.savefig(\"faces.png\")\n",
        "  pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getTime():\n",
        "IST = pytz.timezone('Asia/Kolkata')\n",
        "timeNow = datetime.now(IST)\n",
        "return timeNow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import telepot\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from PIL import Image\n",
        "from PIL import ImageEnhance\n",
        "import pyrebase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from mtcnn.mtcnn import MTCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "V_path = \"../Completed Project/V_19.mp4\"\n",
        "# NonV_path = \"/home/nonv.mp4\"\n",
        "# V_test = \"/home/testv.mp4\" \n",
        "detectViolence(V_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detectViolence(video, limit=None):\n",
        "        trueCount = 0\n",
        "        imageSaved = 0\n",
        "        filename = 'savedImage.jpg'\n",
        "        my_image = 'finalImage.jpg'\n",
        "        face_image = 'faces.png'\n",
        "        sendAlert = 0\n",
        "        location = \"KESAVADASAPURAM\"\n",
        "\n",
        "        print(\"Loading model ...\")\n",
        "        model = load_model('./model_grp29.h5')\n",
        "        Q = deque(maxlen=128)\n",
        "        vs = cv2.VideoCapture(0)\n",
        "        writer = None\n",
        "        (W, H) = (None, None)\n",
        "        count = 0     \n",
        "        while True:\n",
        "            (grabbed, frame) = vs.read()\n",
        "\n",
        "            \n",
        "            if not grabbed:\n",
        "                break\n",
        "            \n",
        "            # if the frame dimensions are empty, grab them\n",
        "            if W is None or H is None:\n",
        "                (H, W) = frame.shape[:2]\n",
        "\n",
        "            # clone the output frame, then convert it from BGR to RGB\n",
        "            # ordering, resize the frame to a fixed 128x128, and then\n",
        "            # perform mean subtraction\n",
        "\n",
        "            \n",
        "            output = frame.copy()\n",
        "           \n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = cv2.resize(frame, (128, 128)).astype(\"float32\")\n",
        "            frame = frame.reshape(128, 128, 3) / 255\n",
        "\n",
        "            # make predictions on the frame and then update the predictions\n",
        "            # queue\n",
        "            preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
        "#             print(\"preds\",preds)\n",
        "            Q.append(preds)\n",
        "\n",
        "            # perform prediction averaging over the current history of\n",
        "            # previous predictions\n",
        "            results = np.array(Q).mean(axis=0)\n",
        "            i = (preds > 0.50)[0]\n",
        "            label = i\n",
        "\n",
        "            text_color = (0, 255, 0) # default : green\n",
        "\n",
        "            if label: # Violence prob\n",
        "                text_color = (0, 0, 255) # red\n",
        "                trueCount = trueCount + 1\n",
        "\n",
        "            else:\n",
        "                text_color = (0, 255, 0)\n",
        "\n",
        "            text = \"Violence: {}\".format(label)\n",
        "            FONT = cv2.FONT_HERSHEY_SIMPLEX \n",
        "\n",
        "            cv2.putText(output, text, (35, 50), FONT,1.25, text_color, 3) \n",
        "\n",
        "            # check if the video writer is None\n",
        "            if writer is None:\n",
        "                # initialize our video writer\n",
        "                fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "                writer = cv2.VideoWriter(\"recordedVideo.avi\", fourcc, 30,(W, H), True)\n",
        "\n",
        "            # write the output frame to disk\n",
        "            writer.write(output)\n",
        "\n",
        "            # show the output image\n",
        "            cv2.imshow('img',output)\n",
        "\n",
        "            if(trueCount == 40):\n",
        "              if(imageSaved == 0):\n",
        "                if(label):\n",
        "                  cv2.imwrite(filename, output)\n",
        "                  imageSaved = 1\n",
        "            \n",
        "              if(sendAlert == 0):\n",
        "                timeMoment = getTime()\n",
        "                imgenhance()\n",
        "                # load image from file\n",
        "                \n",
        "                import matplotlib.pyplot as plt\n",
        "  \n",
        "\n",
        "                # image = plt.imread(image_file)\n",
        "                \n",
        "                # pixels = pyplot.imread(my_image)\n",
        "                pixels = plt.imread(my_image)\n",
        "                # create the detector, using default weights\n",
        "                detector = MTCNN()\n",
        "                # detect faces in the image\n",
        "                faces = detector.detect_faces(pixels)\n",
        "                # display faces on the original image\n",
        "                draw_faces(my_image, faces)\n",
        "                \n",
        "                # bot = telepot.Bot('5309305007:AAGiCHJzRGOF6Bu3QxyMJPigG_k_MQ-NU20') ## GET YOUR OWN TELEGRAM GROUP ID AND BOT ID\n",
        "                # bot.sendMessage(-1001522775837, f\"VIOLENCE ALERT!! \\nLOCATION: {location} \\nTIME: {timeMoment}\")\n",
        "                # bot.sendPhoto(-1001522775837, photo=open('finalImage.jpg', 'rb'))\n",
        "                # bot.sendMessage(-1001522775837, \"FACES OBTAINED\")\n",
        "                # bot.sendPhoto(-1001522775837, photo=open('faces.png', 'rb'))\n",
        "\n",
        "                # storage.child(my_image).put(my_image)\n",
        "                # storage.child(face_image).put(face_image)\n",
        "\n",
        "                # url1 = storage.child(my_image).get_url(user['idToken'])\n",
        "                # url2 = storage.child(face_image).get_url(user['idToken'])\n",
        "                # db.collection(location).add({'date': timeMoment, 'image': url1, 'faces': url2})\n",
        "                sendAlert = 1\n",
        "\n",
        "            key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "            # if the `q` key was pressed, break from the loop\n",
        "            if key == ord(\"q\"):\n",
        "                break\n",
        "        # release the file pointersq\n",
        "        print(\"[INFO] cleaning up...\")\n",
        "        writer.release()\n",
        "        vs.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install prompt_toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "mobilenetv2-model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "330291e952ef2592d61b7857e145d2070e6df96cbb58463d8ee825546f424b29"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
